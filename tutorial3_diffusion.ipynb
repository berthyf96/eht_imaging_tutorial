{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm","authorship_tag":"ABX9TyMpwU7u9ZQobMT/5Aunrz8e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# EHT Tutorial 3: Diffusion-Based Imaging\n","\n","In this tutorial, we use [InverseBench](https://devzhk.github.io/InverseBench/) to perform imaging from EHT M87 data with a pretrained diffusion model. We highlight the [PnP-DM algorithm](https://imaging.cms.caltech.edu/pnpdm/), although other algorithms are available in InverseBench."],"metadata":{"id":"GAphVVHwjNXN"}},{"cell_type":"markdown","source":["## Environment setup"],"metadata":{"id":"zpSt9Wixjg6D"}},{"cell_type":"code","source":["# Install required packages.\n","!pip install ehtim\n","!pip install hydra-core\n","!pip install piq\n","!pip install torch"],"metadata":{"id":"Ia0p_-YNjk1X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Clone `InverseBench` repo.\n","!git clone https://github.com/devzhk/InverseBench\n","%cd InverseBench\n","\n","# Download data for blackhole problem.\n","!wget https://sdsc.osn.xsede.org/ini230004-bucket01/zg89b-mpv16/blackhole.zip\n","!unzip blackhole.zip\n","\n","# Download preprocessed obs file for M87.\n","!wget https://github.com/berthyf96/eht_tutorial/raw/refs/heads/main/obs_095_preprocessed.uvfits\n","\n","# Make a copy of the obs file in the default location.\n","!cp obs_095_preprocessed.uvfits blackhole/measure/obs.uvfits\n","\n","# Download weights of pretrained blackhole diffusion model.\n","!wget https://github.com/devzhk/InverseBench/releases/download/diffusion-prior/blackhole-50k.pt\n","\n","# Move the checkpoint to the default location.\n","!mkdir checkpoints\n","!mv blackhole-50k.pt checkpoints/"],"metadata":{"id":"WNXV5wy1opgS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import libraries.\n","import os\n","import pickle\n","from hydra import initialize_config_dir, compose\n","from hydra.utils import instantiate\n","from omegaconf import OmegaConf\n","\n","import ehtim as eh\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","from torch.utils.data import DataLoader\n","\n","from utils.helper import open_url\n","\n","# Use GPU if available, else CPU.\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"esaQlgO1qu3_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## InverseBench"],"metadata":{"id":"u-d4c1U_j2-m"}},{"cell_type":"markdown","source":["### Set up forward model and inverse solver"],"metadata":{"id":"uF-QFvwlWUtq"}},{"cell_type":"code","source":["# Initialize config with Hydra.\n","abs_config_dir = os.path.abspath('/content/InverseBench/configs')\n","with initialize_config_dir(version_base='1.3', config_dir=abs_config_dir):\n","  config = compose(\n","      config_name='config.yaml',\n","      overrides=[\n","          'problem=blackhole',\n","          'pretrain=blackhole',\n","          'algorithm=pnpdm',\n","          # NOTE: any algorithm hyperparameter overrides would go here\n","          'num_samples=10'\n","      ]\n","  )"],"metadata":{"id":"XryFEuH3e_9A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load pre-trained model.\n","try:\n","  with open_url(config.problem.prior, 'rb') as f:\n","    ckpt = pickle.load(f)\n","    net = ckpt['ema'].to(device)\n","except:\n","  net = instantiate(config.pretrain.model)\n","  ckpt = torch.load(config.problem.prior, map_location=device)\n","  if 'ema' in ckpt.keys():\n","    net.load_state_dict(ckpt['ema'])\n","  else:\n","    net.load_state_dict(ckpt['net'])\n","  net = net.to(device)\n","\n","del ckpt\n","net.eval()"],"metadata":{"id":"sxihJDRqU9l6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# We will use the fiducial total compact flux density for the flux data term.\n","zbl = 0.6\n","\n","# Create forward operator.\n","forward_op = instantiate(\n","    config.problem.model,\n","    device=device,\n","    root='blackhole/measure',\n","    ttype='fast',\n","    ref_flux=zbl,\n","    w1=0.,  # amplitudes weight\n","    w2=1.,  # closure phases weight (default=1)\n","    w3=1.,  # log closure amplitudes weight (default=1)\n","    w4=0.5  # flux constraint weight (default=0.5)\n",")\n","\n","# Set up PnPDP sampling algorithm.\n","algo = instantiate(config.algorithm.method, forward_op=forward_op, net=net)"],"metadata":{"id":"3rJTj9SCaIeY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Create a measurement object from the M87 data"],"metadata":{"id":"D7Rw3VVILx2A"}},{"cell_type":"code","source":["def precalibrate_obs(obs_orig, npix, fov, sys_noise=0.0,\n","                     reverse_taper_uas=0.0, ttype='nfft'):\n","  \"\"\"Precalibrate preprocessed Obsdata as in eht-imaging M87 pipeline.\"\"\"\n","  obs = obs_orig.copy()\n","\n","  # Reverse taper the observation: this enforces a maximum resolution on\n","  # reconstructed features.\n","  if reverse_taper_uas > 0:\n","    obs = obs.reverse_taper(reverse_taper_uas * eh.RADPERUAS)\n","\n","  # Add non-closing systematic noise to the observation.\n","  obs = obs.add_fractional_noise(sys_noise)\n","\n","  # Make a copy of the initial data\n","  # (before any self-calibration but after the taper)\n","  obs_sc_init = obs.copy()\n","\n","  # Self-calibrate the LMT to a Gaussian model\n","  # (Refer to Section 4's \"Pre-Imaging Considerations\")\n","  obs_LMT = obs_sc_init.flag_uvdist(uv_max=2e9) # only consider the\n","                                                # short baselines (LMT-SMT)\n","  if reverse_taper_uas > 0:\n","    # Start with original data that had no reverse taper applied.\n","    # Re-taper, if necessary.\n","    obs_LMT = obs_LMT.taper(reverse_taper_uas * eh.RADPERUAS)\n","\n","  # Make a Gaussian image that would result in the LMT-SMT baseline visibility\n","  # amplitude as estimated in Section 4's \"Pre-Imaging Considerations\".\n","  # This is achieved with a Gaussian of size 60 microarcseconds and total flux\n","  # of 0.6 Jy.\n","  gausspriorLMT = eh.image.make_square(obs, npix, fov)\n","  gausspriorLMT = gausspriorLMT.add_gauss(\n","    0.6,\n","    (60.0 * eh.RADPERUAS, 60.0 * eh.RADPERUAS, 0, 0, 0))\n","\n","  # Self-calibrate the LMT visibilities to the gausspriorLMT image\n","  # to enforce the estimated LMT-SMT visibility amplitude.\n","  caltab = eh.selfcal(obs_LMT, gausspriorLMT, sites=['LM'], gain_tol=1.0,\n","                      method='both', ttype=ttype, caltable=True)\n","\n","  # Supply the calibration solution to the full (and potentially tapered)\n","  # dataset.\n","  obs = caltab.applycal(obs, interp='nearest', extrapolate=True)\n","\n","  return obs"],"metadata":{"id":"Va5rQg5pySmn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the preprocessed M87 observation data.\n","obs = eh.obsdata.load_uvfits('obs_095_preprocessed.uvfits')\n","\n","# We found that precalibrating the data helps with the diffusion model results.\n","obs = precalibrate_obs(\n","    obs,\n","    npix=64,\n","    fov=128 * eh.RADPERUAS,\n","    sys_noise=0.03,\n","    ttype='fast'\n",")"],"metadata":{"id":"xD9qlk32y76W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The diffusion model was trained on images whose pixels are between [0, 1],\n","# so we have to divide the measured amplitudes by a multiplier to get them\n","# closer to a value expected by the diffusion model. We will later multiply the\n","# diffusion model's output by the same multiplier to get an image that has the\n","# actual total flux.\n","# We'll assume a total flux based on a Gaussian prior.\n","im = eh.image.make_square(obs, npix=64, fov=128 * eh.RADPERUAS)\n","prior_fwhm = 40 * eh.RADPERUAS\n","im = im.add_gauss(zbl, (prior_fwhm, prior_fwhm, 0, 0, 0))\n","multiplier = im.ivec.max()\n","\n","# Uncomment the line below to instead define the flux multiplier based on the\n","# total flux of a GRMHD image.\n","# multiplier = forward_op.ref_multiplier\n","\n","print(multiplier)"],"metadata":{"id":"pepBc8rhKqe0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get the amplitudes and their sigmas.\n","obs.add_amp()\n","amp = torch.from_numpy(\n","    obs.amp['amp'])[None, None, :, None].float().to(device)\n","sigmaamp = torch.from_numpy(\n","    obs.amp['sigma'])[None, None, :, None].float().to(device)\n","\n","# Rescale the amplitudes and their sigmas to be more in the range expected for\n","# an image with a max pixel value of 1.\n","amp = amp / multiplier\n","sigmaamp = sigmaamp / multiplier"],"metadata":{"id":"T7TTgnnuaxdD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get closure phases and their sigmas from the minimal set of closure phases.\n","obs.add_cphase(count='min')\n","cp = torch.from_numpy(\n","    obs.cphase['cphase'])[None, None, :, None].float().to(device) * eh.DEGREE\n","sigmacp = torch.from_numpy(\n","    obs.cphase['sigmacp'])[None, None, :, None].float().to(device) * eh.DEGREE"],"metadata":{"id":"8rZHQO69KsT-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get log closure amplitudes and their sigmas from the minimal set of\n","# closure ampltudes.\n","obs.add_logcamp(count='min')\n","camp = torch.from_numpy(\n","    obs.logcamp['camp'])[None, None, :, None].float().to(device)\n","sigmaca = torch.from_numpy(\n","    obs.logcamp['sigmaca'])[None, None, :, None].float().to(device)"],"metadata":{"id":"eHCgQDPMMnAZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The flux constraint is based on the assumed compact flux density.\n","flux = torch.tensor([zbl])[None, None, :, None].float().to(device)\n","\n","# We also rescale the assumed flux to be closer to that of an image whose\n","# max pixel value is 1.\n","flux = flux / multiplier"],"metadata":{"id":"XxIPRMfuMn5q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The observation `y` is a concatenation of the amplitude, closure phase,\n","# log closure amplitude, and flux data.\n","y = torch.cat([amp, sigmaamp, cp, sigmacp, camp, sigmaca, flux], dim=2)"],"metadata":{"id":"JDTBEtviLUvA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Inference"],"metadata":{"id":"SIrTYMHrL-iR"}},{"cell_type":"code","source":["# Run the algorithm.\n","print(f'Running inference on M87 data...', flush=True)\n","recon = algo.inference(y, num_samples=config.num_samples)\n","print('Peak GPU memory usage: '\n","      f'{torch.cuda.max_memory_allocated() / 1024 ** 3:.2f} GB')\n","\n","result_dict = {\n","  'observation': y,\n","  'recon': forward_op.unnormalize(recon),\n","}"],"metadata":{"id":"0Kx3_CmpgYgN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate chi-squared metrics.\n","cp_chi2s, logcamp_chi2s = forward_op.evaluate_chisq(result_dict['recon'], y)\n","\n","# Plot a histogram of the closure phase chi-squared values.\n","plt.hist(cp_chi2s.cpu().numpy())\n","plt.xlabel('closure phase chi2')\n","plt.ylabel('# samples')\n","plt.show()"],"metadata":{"id":"rXo-VDoHfSvf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Show the image samples and their chi-squared values.\n","recon_images = result_dict['recon'].cpu().permute(0, 2, 3, 1).numpy()\n","\n","fig, axs = plt.subplots(1, 10, figsize=(20, 3))\n","for ax, image, cp_chi2, logcamp_chi2 in zip(axs, recon_images,\n","                                            cp_chi2s, logcamp_chi2s):\n","  ax.imshow(image, cmap='afmhot')\n","  ax.axis('off')\n","  ax.set_title(f\"cp $\\chi^2$: {cp_chi2:.2f}\\nlogca $\\chi^2$: {logcamp_chi2:.2f}\")\n","plt.show()"],"metadata":{"id":"kQle300oWjME"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Look at unconditional samples from the diffusion model"],"metadata":{"id":"60zC_QiSWgEW"}},{"cell_type":"code","source":["# Create a new config for unconditional sampling.\n","with initialize_config_dir(version_base='1.3', config_dir=abs_config_dir):\n","  config = compose(\n","      config_name='config.yaml',\n","      overrides=[\n","          'problem=blackhole',\n","          'pretrain=blackhole',\n","          'algorithm=uncond',\n","          'num_samples=10'\n","      ]\n","  )\n","\n","# Set up unconditional sampling algorithm.\n","algo = instantiate(config.algorithm.method, forward_op=forward_op, net=net)\n","\n","# Use dummy measurements.\n","dummy_y = torch.zeros((config.num_samples, 1, 1, 1)).to(device)\n","\n","# Run the algorithm.\n","uncond_recon = algo.inference(dummy_y, num_samples=config.num_samples)\n","\n","# Renormalize to [0, 1].\n","uncond_recon = forward_op.unnormalize(uncond_recon)\n","\n","# Reformat to NumPy.\n","uncond_images = uncond_recon.cpu().permute(0, 2, 3, 1).numpy()"],"metadata":{"id":"8WmqpYljXfq-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Show unconditional samples.\n","fig, axs = plt.subplots(1, 10, figsize=(20, 3))\n","for ax, image in zip(axs, uncond_images):\n","  ax.imshow(image, cmap='afmhot')\n","  ax.axis('off')\n","plt.show()"],"metadata":{"id":"n285XRkrfIe4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QDcvksbxXwio"},"execution_count":null,"outputs":[]}]}